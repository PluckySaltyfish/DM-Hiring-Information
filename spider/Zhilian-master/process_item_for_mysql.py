#!/usr/bin/env python
# -*- coding: utf-8 -*-

import redis
import MySQLdb
import json
def process_item():

    #创建redis连接
    city = ['其他', '鞍山', '安顺', '安阳', '安康', '安庆', '阿坝', '阿克苏', '阿拉尔',
            '阿拉善盟', '阿勒泰', '阿里', '安达', '北京', '包头', '宝鸡', '保定',
            '滨州', '亳州', '蚌埠', '北海', '白银', '白城', '白山', '毕节', '巴中',
            '巴彦淖尔', '巴音郭楞', '百色', '保山', '本溪', '博尔塔拉', '北屯区',
            '重庆', '成都', '长春', '长株潭', '沧州', '常熟', '常德', '常州',
            '滁州', '承德', '郴州', '潮州', '长治', '赤峰', '池州', '昌都',
            '昌吉', '昌图', '长沙', '朝阳', '城阳', '崇左', '楚雄', '大连',
            '东莞', '大庆', '丹东', '德阳', '德州', '东营', '大同', '大理',
            '达州', '大兴安岭', '儋州', '德宏', '迪庆', '定西', '东港',
            '鄂尔多斯', '鄂州', '恩施', '峨眉', '佛山', '福州', '抚顺',
            '阜阳', '抚州', '防城港', '阜新', '广州', '赣州', '贵阳',
            '甘肃', '桂林', '广元', '广安', '甘南', '甘孜', '公安', '公主岭',
            '固原', '贵港', '果洛', '哈尔滨', '海口', '邯郸', '杭州', '合肥',
            '衡阳', '衡水', '呼和浩特', '湖州', '淮安', '菏泽', '淮北', '汉中',
            '呼伦贝尔', '葫芦岛', '惠州', '珲春', '鹤壁', '淮南', '黄冈', '怀化',
            '黄石', '黄山', '河源', '黑河', '哈密', '海北', '海城', '海东', '海南州',
            '海西', '海阳', '和田', '河池', '贺州', '鹤岗', '红河', '黄岛', '黄南', '济南',
            '吉林省', '济宁', '嘉兴', '江门', '江阴', '金华', '荆州', '九江', '焦作', '揭阳',
            '佳木斯', '锦州', '晋中', '晋城', '吉安', '景德镇', '济源', '吉首市', '鸡西', '即墨',
            '简阳', '胶南', '胶州', '金昌', '荆门', '酒泉', '开封', '昆明', '昆山', '开平', '喀什',
            '开原', '克拉玛依', '克孜勒苏', '奎屯市', '兰州', '廊坊', '连云港', '聊城', '临沂', '柳州',
            '洛阳', '漯河', '拉萨', '六盘水', '莱芜', '乐山', '辽阳', '临汾', '龙岩', '丽水', '六安',
            '吕梁', '辽源', '娄底', '泸州', '来宾', '莱西', '丽江', '凉山', '林芝', '临沧', '临夏', '陇南',
            '马鞍山', '绵阳', '牡丹江', '梅州', '茂名', '蒙自市', '满洲里', '眉山', '南京', '南昌', '南充',
            '南宁', '南阳', '南通', '宁波', '宁夏', '南平', '宁德', '内江', '那曲', '怒江', '平顶山',
            '莆田', '濮阳', '盘锦', '普宁', '萍乡', '攀枝花', '平度', '平凉', '普洱', '青岛', '秦皇岛',
            '青海', '清远', '泉州', '齐齐哈尔', '曲靖', '衢州', '黔西南', '潜江', '黔东南', '钦州',
            '庆阳', '琼海', '日照', '日喀则', '上海', '深圳', '沈阳', '石家庄', '三亚', '汕头', '商丘',
            '绍兴', '四平', '苏州', '宿迁', '宿州', '随州', '上饶', '邵阳', '十堰', '三门峡', '商洛',
            '松原', '遂宁', '韶关', '三明', '绥化', '汕尾', '山南', '尚志', '神农架', '石河子', '双城',
            '双鸭山', '朔州', '绥芬河', '天津', '台州', '太原', '泰安', '泰州', '唐山', '铁岭', '铜川',
            '通辽', '通化', '铜陵', '天水', '铜仁', '太仓市', '天门', '图木舒克', '吐鲁番', '武汉', '威海',
            '潍坊', '温州', '乌鲁木齐', '无锡', '芜湖', '渭南', '文昌', '文山', '乌海', '乌兰察布', '乌审旗',
            '乌苏', '吴忠', '梧州', '五家渠', '武威', '武穴', '西安', '西藏', '厦门', '咸阳', '襄阳', '新乡',
            '徐州', '许昌', '信阳', '邢台', '新疆', '新余', '孝感', '宣城', '咸宁', '西宁', '西平', '锡林郭勒盟',
            '湘潭', '湘西', '忻州', '兴安盟', '兴城', '兴平', '西咸新区', '烟台', '盐城', '扬州', '宜昌', '义乌',
            '营口', '榆林', '玉林', '运城', '宜兴', '岳阳', '宜宾', '延安', '延边', '玉溪', '阳江', '益阳', '宜春',
            '银川', '阳泉', '永州', '云浮', '鹰潭', '雅安', '杨凌', '伊春', '伊犁', '宜城', '永济市', '玉树', '郑州',
            '枣庄', '湛江', '张家港', '张家口', '漳州', '肇庆', '镇江', '中山', '珠海', '淄博', '遵义', '驻马店', '周口',
            '自贡', '舟山', '张掖', '张家界', '昭通', '肇东市', '中卫', '株洲', '资阳', '遵化']
    redis_cli = redis.Redis(host='127.0.0.1',port=6379,db=0)

    mysql_cli = MySQLdb.connect(host='127.0.0.1',port=3306,user='root',passwd='geronimo',db='crawler')
    url_arg0 = "http://sou.zhaopin.com/jobs/searchresult.ashx?jl="
    url_arg1 = "&kw=大数据&sm=1&p=1"

    index = 0
    redis_cli.lpush("zlspider:start_urls", url_arg0 + city[index] + url_arg1)

    while True:
        source, data = redis_cli.blpop('zl:items')

        item = json.loads(data)
        cursor = mysql_cli.cursor()

        str = "INSERT into zl(j_name, c_name, c_nature, c_scale,description, w_place, w_field, w_experience, education, s_min, s_max, t_publish, vacancies,welfare,url) VALUES('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s');" \
              % (item['positionName'],item['companyName'],item['companyNature'],\
                       item['companyScale'],item['positionDescription'],item['location'],\
                       item['positionField'],item['experience'],item['degree'],item['minSalary'],\
                       item['maxSalary'],item['publishTime'],item['vacancies'],item['welfare'],item['subUrl'])

        print str
        cursor.execute(str)

        mysql_cli.commit()

        cursor.close()
        if not redis_cli.llen('zl:items') != 0:
            if index < len(city) - 1:
                index = index + 1
                redis_cli.lpush("zlspider:start_urls", url_arg0 + city[index] + url_arg1)




if __name__ == '__main__':
    process_item()